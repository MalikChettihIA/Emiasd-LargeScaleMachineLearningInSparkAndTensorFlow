# OneHotEncoder dans Spark ML - Explication Complète

## Vue d'ensemble

**OneHotEncoder** est un transformateur de Spark ML qui convertit des variables catégorielles (préalablement indexées) en vecteurs binaires. Cette technique est essentielle pour les algorithmes de machine learning qui nécessitent des features continues, comme la régression logistique.

## Analyse du code

```scala
import org.apache.spark.ml.feature.OneHotEncoder

val oneHotEncoder = new OneHotEncoder()
  .setInputCols(Array("indexed_age", "indexed_income"))
  .setOutputCols(Array("category_age", "category_income"))
  .setDropLast(false)

val oneHotEncoderModel = oneHotEncoder.fit(ageIncomeIndexed)
val encoded = oneHotEncoderModel.transform(ageIncomeIndexed)
encoded.show()
```

## Explication détaillée

### 1. Import et création de l'encoder
```scala
import org.apache.spark.ml.feature.OneHotEncoder

val oneHotEncoder = new OneHotEncoder()
```
Import de la classe OneHotEncoder et création d'une instance.

### 2. Configuration des colonnes d'entrée et de sortie
```scala
.setInputCols(Array("indexed_age", "indexed_income"))
.setOutputCols(Array("category_age", "category_income"))
```
- **setInputCols** : Spécifie les colonnes d'entrée (déjà indexées par StringIndexer)
- **setOutputCols** : Définit les noms des colonnes de sortie (vecteurs binaires)

### 3. Paramètre setDropLast
```scala
.setDropLast(false)
```
**Point crucial** : Détermine si la dernière catégorie doit être supprimée.
- `false` : Conserve toutes les catégories (recommandé pour éviter la perte d'information)
- `true` : Supprime la dernière catégorie pour éviter la colinéarité

### 4. Entraînement et transformation
```scala
val oneHotEncoderModel = oneHotEncoder.fit(ageIncomeIndexed)
val encoded = oneHotEncoderModel.transform(ageIncomeIndexed)
```
- **fit()** : Analyse les données pour déterminer le nombre de catégories
- **transform()** : Applique l'encodage one-hot

## Principe du One-Hot Encoding

### Transformation conceptuelle

**Données d'entrée** (après StringIndexer) :
```scala
+----------+-------------+
|indexed_age|indexed_income|
+----------+-------------+
|       0.0|          1.0|  // senior, medium
|       1.0|          0.0|  // young, high  
|       2.0|          1.0|  // middle, medium
|       0.0|          2.0|  // senior, low
```

**Après OneHotEncoder** :
```scala
+----------+-------------+-------------+-------------+
|indexed_age|indexed_income|category_age |category_income|
+----------+-------------+-------------+-------------+
|       0.0|          1.0|(3,[0],[1.0])|(3,[1],[1.0])|
|       1.0|          0.0|(3,[1],[1.0])|(3,[0],[1.0])|
|       2.0|          1.0|(3,[2],[1.0])|(3,[2],[1.0])|
|       0.0|          2.0|(3,[0],[1.0])|(3,[2],[1.0])|
```

### Interprétation des vecteurs sparse

Le format `(3,[0],[1.0])` signifie :
- **3** : Taille du vecteur (3 catégories pour age)
- **[0]** : Position non-nulle (indice 0)
- **[1.0]** : Valeur à cette position

**Équivalents en format dense** :
- `(3,[0],[1.0])` = `[1.0, 0.0, 0.0]` (senior)
- `(3,[1],[1.0])` = `[0.0, 1.0, 0.0]` (young)
- `(3,[2],[1.0])` = `[0.0, 0.0, 1.0]` (middle)

## Impact du paramètre setDropLast

### Avec setDropLast(false) - Recommandé
```scala
// 3 catégories d'âge → vecteur de taille 3
senior  → [1.0, 0.0, 0.0]
young   → [0.0, 1.0, 0.0]
middle  → [0.0, 0.0, 1.0]
```
**Avantage** : Aucune perte d'information, toutes les catégories sont représentées.

### Avec setDropLast(true) - Attention !
```scala
// 3 catégories d'âge → vecteur de taille 2 (middle supprimé)
senior  → [1.0, 0.0]
young   → [0.0, 1.0]
middle  → [0.0, 0.0]  // Implicite
```
**Problème** : La catégorie "middle" devient indistinguable d'un vecteur nul !

## Exemple concret avec données réelles

### Dataset d'origine
```scala
case class Person(age: String, income: String, student: String, credit_rating: String, buys_computer: String)

val data = Seq(
    Person("young", "high", "no", "fair", "no"),
    Person("middle", "high", "no", "fair", "yes"),
    Person("senior", "medium", "no", "fair", "yes"),
    Person("senior", "low", "yes", "fair", "yes")
).toDF()
```

### Après StringIndexer
```scala
// Fréquences : senior=2, young=1, middle=1
// Indices    : senior=0, young=1, middle=2
+-----+------+----------+-------------+
| age |income|indexed_age|indexed_income|
+-----+------+----------+-------------+
|young| high |       1.0|          0.0|
|middle|high |       2.0|          0.0|
|senior|medium|       0.0|          1.0|
|senior| low  |       0.0|          2.0|
```

### Après OneHotEncoder (setDropLast=false)
```scala
+----------+-------------+-------------+---------------+
|indexed_age|indexed_income|category_age |category_income|
+----------+-------------+-------------+---------------+
|       1.0|          0.0|(3,[1],[1.0])|(3,[0],[1.0]) |
|       2.0|          0.0|(3,[2],[1.0])|(3,[0],[1.0]) |
|       0.0|          1.0|(3,[0],[1.0])|(3,[1],[1.0]) |
|       0.0|          2.0|(3,[0],[1.0])|(3,[2],[1.0]) |
```

### Conversion en format dense pour la visualisation
```scala
import org.apache.spark.ml.linalg.SparseVector
import org.apache.spark.sql.functions.udf

val toArray = udf((v: SparseVector) => v.toArray)
val denseData = encoded.withColumn("age_dense", toArray($"category_age"))
                      .withColumn("income_dense", toArray($"category_income"))

denseData.select("age_dense", "income_dense").show(truncate=false)
```

**Résultat** :
```scala
+-------------------+-------------------+
|age_dense          |income_dense       |
+-------------------+-------------------+
|[0.0, 1.0, 0.0]    |[1.0, 0.0, 0.0]    | // young, high
|[0.0, 0.0, 1.0]    |[1.0, 0.0, 0.0]    | // middle, high
|[1.0, 0.0, 0.0]    |[0.0, 1.0, 0.0]    | // senior, medium
|[1.0, 0.0, 0.0]    |[0.0, 0.0, 1.0]    | // senior, low
```

## Intégration dans un pipeline complet

```scala
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder, VectorAssembler}
import org.apache.spark.ml.classification.LogisticRegression

// 1. Indexation des variables catégorielles
val ageIndexer = new StringIndexer()
    .setInputCol("age")
    .setOutputCol("indexed_age")

val incomeIndexer = new StringIndexer()
    .setInputCol("income")
    .setOutputCol("indexed_income")

// 2. One-hot encoding
val oneHotEncoder = new OneHotEncoder()
    .setInputCols(Array("indexed_age", "indexed_income"))
    .setOutputCols(Array("age_vec", "income_vec"))
    .setDropLast(false)

// 3. Assemblage des features
val assembler = new VectorAssembler()
    .setInputCols(Array("age_vec", "income_vec"))
    .setOutputCol("features")

// 4. Indexation du label
val labelIndexer = new StringIndexer()
    .setInputCol("buys_computer")
    .setOutputCol("label")

// 5. Modèle de classification
val lr = new LogisticRegression()

// 6. Pipeline complet
val pipeline = new Pipeline()
    .setStages(Array(ageIndexer, incomeIndexer, oneHotEncoder, assembler, labelIndexer, lr))

val model = pipeline.fit(data)
val predictions = model.transform(data)
```

## Comparaison setDropLast : true vs false

### Exemple pratique avec 3 catégories

**Données d'entrée** :
```scala
val testData = Seq((0.0), (1.0), (2.0)).toDF("category")
```

**Avec setDropLast(false)** :
```scala
val encoder1 = new OneHotEncoder()
    .setInputCols(Array("category"))
    .setOutputCols(Array("encoded"))
    .setDropLast(false)

// Résultat : vecteurs de taille 3
// 0.0 → (3,[0],[1.0]) = [1.0, 0.0, 0.0]
// 1.0 → (3,[1],[1.0]) = [0.0, 1.0, 0.0]  
// 2.0 → (3,[2],[1.0]) = [0.0, 0.0, 1.0]
```

**Avec setDropLast(true)** :
```scala
val encoder2 = new OneHotEncoder()
    .setInputCols(Array("category"))
    .setOutputCols(Array("encoded"))
    .setDropLast(true)

// Résultat : vecteurs de taille 2
// 0.0 → (2,[0],[1.0]) = [1.0, 0.0]
// 1.0 → (2,[1],[1.0]) = [0.0, 1.0]
// 2.0 → (2,[],[])     = [0.0, 0.0]  ⚠️ Problématique !
```

## Cas d'usage et recommandations

### Quand utiliser OneHotEncoder

1. **Variables catégorielles nominales** : Pas d'ordre naturel (couleur, région)
2. **Algorithmes linéaires** : Régression logistique, SVM linéaire
3. **Éviter l'ordre artificiel** : StringIndexer crée un ordre qui peut biaiser le modèle

### Alternatives selon le contexte

```scala
// Pour des variables ordinales (avec ordre naturel)
// Conserver l'indexation numérique peut être suffisant
val ordinalFeature = stringIndexer.transform(data)  // Garder les indices

// Pour des variables avec beaucoup de catégories
// Considérer d'autres techniques comme l'embedding
```

### Recommandations pratiques

1. **Toujours utiliser setDropLast(false)** pour éviter la perte d'information
2. **Préprocessing en pipeline** : Intégrer dans un pipeline pour la reproductibilité
3. **Gestion mémoire** : OneHotEncoder peut créer des vecteurs très larges avec beaucoup de catégories
4. **Test des dimensions** : Vérifier les tailles des vecteurs après transformation

## Debugging et validation

### Vérification des dimensions
```scala
// Compter les catégories uniques
data.select("indexed_age").distinct().count()  // Nombre de catégories

// Vérifier la taille des vecteurs après encodage
val sampleVector = encoded.select("category_age").first().getAs[Vector]("category_age")
println(s"Taille du vecteur: ${sampleVector.size}")
```

### Inspection du mapping
```scala
// Afficher le mapping original → index → one-hot
ageIncomeIndexed.select("age", "indexed_age").distinct().orderBy("indexed_age").show()
encoded.select("indexed_age", "category_age").distinct().orderBy("indexed_age").show()
```

### Validation de l'encodage
```scala
// Vérifier qu'il n'y a qu'un seul 1.0 par vecteur
import org.apache.spark.ml.linalg.Vector

val validateOneHot = udf((v: Vector) => {
    val sum = v.toArray.sum
    sum == 1.0  // Doit être exactement 1.0
})

val validation = encoded.withColumn("is_valid", validateOneHot($"category_age"))
validation.filter(!$"is_valid").count()  // Doit être 0
```

## Optimisations et considérations de performance

### Gestion des vecteurs sparse
```scala
// OneHotEncoder produit naturellement des vecteurs sparse
// Utiliser VectorAssembler pour combiner efficacement
val assembler = new VectorAssembler()
    .setInputCols(Array("category_age", "category_income"))
    .setOutputCol("features")

// Le résultat reste sparse automatiquement
val assembled = assembler.transform(encoded)
assembled.select("features").show(truncate=false)
```

### Réduction de dimensionnalité si nécessaire
```scala
// Pour des variables avec beaucoup de catégories, considérer
import org.apache.spark.ml.feature.PCA

val pca = new PCA()
    .setInputCol("features")
    .setOutputCol("pca_features")
    .setK(10)  // Réduire à 10 dimensions

val pcaModel = pca.fit(assembled)
val reduced = pcaModel.transform(assembled)
```

## Conclusion

OneHotEncoder est un transformateur essentiel pour convertir les variables catégorielles en format numérique compatible avec les algorithmes de machine learning. Le paramètre `setDropLast(false)` est crucial pour éviter la perte d'information. L'intégration dans des pipelines avec StringIndexer et VectorAssembler crée un workflow de preprocessing robuste et reproductible pour les projets de machine learning à grande échelle.

### Points clés à retenir

- **Prérequis** : Utiliser StringIndexer avant OneHotEncoder
- **setDropLast(false)** : Recommandé pour conserver toute l'information
- **Format sparse** : Optimisation automatique de la mémoire
- **Pipeline integration** : Composant standard des workflows ML
- **Validation** : Toujours vérifier les dimensions et la cohérence des transformations